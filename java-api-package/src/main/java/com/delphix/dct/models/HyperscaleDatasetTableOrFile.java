/*
 * Delphix DCT API
 * Delphix DCT API
 *
 * The version of the OpenAPI document: 3.10.0
 * Contact: support@delphix.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package com.delphix.dct.models;

import java.util.Objects;
import com.delphix.dct.models.HyperscaleColumnOrField;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.lang.reflect.Type;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import com.delphix.dct.JSON;

/**
 * A table or file which is part of a hyperscale dataset.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-04-03T12:02:33.321319+05:30[Asia/Kolkata]", comments = "Generator version: 7.4.0")
public class HyperscaleDatasetTableOrFile {
  public static final String SERIALIZED_NAME_ID = "id";
  @SerializedName(SERIALIZED_NAME_ID)
  private String id;

  public static final String SERIALIZED_NAME_SCHEMA_NAME = "schema_name";
  @SerializedName(SERIALIZED_NAME_SCHEMA_NAME)
  private String schemaName;

  public static final String SERIALIZED_NAME_TABLE_NAME = "table_name";
  @SerializedName(SERIALIZED_NAME_TABLE_NAME)
  private String tableName;

  public static final String SERIALIZED_NAME_COLLECTION_NAME = "collection_name";
  @SerializedName(SERIALIZED_NAME_COLLECTION_NAME)
  private String collectionName;

  public static final String SERIALIZED_NAME_DATABASE_NAME = "database_name";
  @SerializedName(SERIALIZED_NAME_DATABASE_NAME)
  private String databaseName;

  public static final String SERIALIZED_NAME_FILTER_KEY = "filter_key";
  @SerializedName(SERIALIZED_NAME_FILTER_KEY)
  private String filterKey;

  public static final String SERIALIZED_NAME_COLUMN_ARRAY_ROWS = "column_array_rows";
  @SerializedName(SERIALIZED_NAME_COLUMN_ARRAY_ROWS)
  private Long columnArrayRows;

  public static final String SERIALIZED_NAME_UNLOAD_SPLIT = "unload_split";
  @SerializedName(SERIALIZED_NAME_UNLOAD_SPLIT)
  private Long unloadSplit;

  public static final String SERIALIZED_NAME_STREAM_SIZE = "stream_size";
  @SerializedName(SERIALIZED_NAME_STREAM_SIZE)
  private Long streamSize;

  public static final String SERIALIZED_NAME_END_OF_RECORD = "end_of_record";
  @SerializedName(SERIALIZED_NAME_END_OF_RECORD)
  private String endOfRecord;

  public static final String SERIALIZED_NAME_DELIMITER = "delimiter";
  @SerializedName(SERIALIZED_NAME_DELIMITER)
  private String delimiter;

  public static final String SERIALIZED_NAME_ENCLOSURE = "enclosure";
  @SerializedName(SERIALIZED_NAME_ENCLOSURE)
  private String enclosure;

  public static final String SERIALIZED_NAME_ENCLOSURE_ESCAPE_CHARACTER = "enclosure_escape_character";
  @SerializedName(SERIALIZED_NAME_ENCLOSURE_ESCAPE_CHARACTER)
  private String enclosureEscapeCharacter;

  public static final String SERIALIZED_NAME_ESCAPE_ENCLOSURE_ESCAPE_CHARACTER = "escape_enclosure_escape_character";
  @SerializedName(SERIALIZED_NAME_ESCAPE_ENCLOSURE_ESCAPE_CHARACTER)
  private Boolean escapeEnclosureEscapeCharacter;

  public static final String SERIALIZED_NAME_HAS_HEADERS = "has_headers";
  @SerializedName(SERIALIZED_NAME_HAS_HEADERS)
  private Boolean hasHeaders;

  public static final String SERIALIZED_NAME_UNIQUE_SOURCE_FILES_IDENTIFIER = "unique_source_files_identifier";
  @SerializedName(SERIALIZED_NAME_UNIQUE_SOURCE_FILES_IDENTIFIER)
  private String uniqueSourceFilesIdentifier;

  public static final String SERIALIZED_NAME_SOURCE_FILES = "source_files";
  @SerializedName(SERIALIZED_NAME_SOURCE_FILES)
  private List<String> sourceFiles;

  public static final String SERIALIZED_NAME_PERFORM_JOIN = "perform_join";
  @SerializedName(SERIALIZED_NAME_PERFORM_JOIN)
  private Boolean performJoin;

  public static final String SERIALIZED_NAME_MASKING_INVENTORY = "masking_inventory";
  @SerializedName(SERIALIZED_NAME_MASKING_INVENTORY)
  private List<HyperscaleColumnOrField> maskingInventory;

  public HyperscaleDatasetTableOrFile() {
  }

  public HyperscaleDatasetTableOrFile id(String id) {
    this.id = id;
    return this;
  }

   /**
   * The ID of the Hyperscale Dataset table or file.
   * @return id
  **/
  @javax.annotation.Nullable
  public String getId() {
    return id;
  }

  public void setId(String id) {
    this.id = id;
  }


  public HyperscaleDatasetTableOrFile schemaName(String schemaName) {
    this.schemaName = schemaName;
    return this;
  }

   /**
   * Name of the table schema (Oracle/MSSql only).
   * @return schemaName
  **/
  @javax.annotation.Nullable
  public String getSchemaName() {
    return schemaName;
  }

  public void setSchemaName(String schemaName) {
    this.schemaName = schemaName;
  }


  public HyperscaleDatasetTableOrFile tableName(String tableName) {
    this.tableName = tableName;
    return this;
  }

   /**
   * Name of the table (Oracle/MSSql only).
   * @return tableName
  **/
  @javax.annotation.Nullable
  public String getTableName() {
    return tableName;
  }

  public void setTableName(String tableName) {
    this.tableName = tableName;
  }


  public HyperscaleDatasetTableOrFile collectionName(String collectionName) {
    this.collectionName = collectionName;
    return this;
  }

   /**
   * Name of the collection (MongoDB only).
   * @return collectionName
  **/
  @javax.annotation.Nullable
  public String getCollectionName() {
    return collectionName;
  }

  public void setCollectionName(String collectionName) {
    this.collectionName = collectionName;
  }


  public HyperscaleDatasetTableOrFile databaseName(String databaseName) {
    this.databaseName = databaseName;
    return this;
  }

   /**
   * Name of the database (MongoDB only).
   * @return databaseName
  **/
  @javax.annotation.Nullable
  public String getDatabaseName() {
    return databaseName;
  }

  public void setDatabaseName(String databaseName) {
    this.databaseName = databaseName;
  }


  public HyperscaleDatasetTableOrFile filterKey(String filterKey) {
    this.filterKey = filterKey;
    return this;
  }

   /**
   * The unique database column field to filter the source data.
   * @return filterKey
  **/
  @javax.annotation.Nullable
  public String getFilterKey() {
    return filterKey;
  }

  public void setFilterKey(String filterKey) {
    this.filterKey = filterKey;
  }


  public HyperscaleDatasetTableOrFile columnArrayRows(Long columnArrayRows) {
    this.columnArrayRows = columnArrayRows;
    return this;
  }

   /**
   * The number of column array rows to be used by the sqlldr oracle utility which determines the number of rows loaded before the stream buffer is built.
   * @return columnArrayRows
  **/
  @javax.annotation.Nullable
  public Long getColumnArrayRows() {
    return columnArrayRows;
  }

  public void setColumnArrayRows(Long columnArrayRows) {
    this.columnArrayRows = columnArrayRows;
  }


  public HyperscaleDatasetTableOrFile unloadSplit(Long unloadSplit) {
    this.unloadSplit = unloadSplit;
    return this;
  }

   /**
   * The number of unloaded files to be generated from the source database.
   * @return unloadSplit
  **/
  @javax.annotation.Nullable
  public Long getUnloadSplit() {
    return unloadSplit;
  }

  public void setUnloadSplit(Long unloadSplit) {
    this.unloadSplit = unloadSplit;
  }


  public HyperscaleDatasetTableOrFile streamSize(Long streamSize) {
    this.streamSize = streamSize;
    return this;
  }

   /**
   * Long The stream size to be used by the sqlldr oracle utility which specifies the size (in bytes) of the data stream sent from the client to the server.
   * @return streamSize
  **/
  @javax.annotation.Nullable
  public Long getStreamSize() {
    return streamSize;
  }

  public void setStreamSize(Long streamSize) {
    this.streamSize = streamSize;
  }


  public HyperscaleDatasetTableOrFile endOfRecord(String endOfRecord) {
    this.endOfRecord = endOfRecord;
    return this;
  }

   /**
   * The end of line character. Support values are \\n, \\r  and \\r\\n (Delimited files only).
   * @return endOfRecord
  **/
  @javax.annotation.Nullable
  public String getEndOfRecord() {
    return endOfRecord;
  }

  public void setEndOfRecord(String endOfRecord) {
    this.endOfRecord = endOfRecord;
  }


  public HyperscaleDatasetTableOrFile delimiter(String delimiter) {
    this.delimiter = delimiter;
    return this;
  }

   /**
   * The single character length delimiter used in source files (Delimited files only).
   * @return delimiter
  **/
  @javax.annotation.Nullable
  public String getDelimiter() {
    return delimiter;
  }

  public void setDelimiter(String delimiter) {
    this.delimiter = delimiter;
  }


  public HyperscaleDatasetTableOrFile enclosure(String enclosure) {
    this.enclosure = enclosure;
    return this;
  }

   /**
   * The single character length quote character used in the source files (Delimited files only).
   * @return enclosure
  **/
  @javax.annotation.Nullable
  public String getEnclosure() {
    return enclosure;
  }

  public void setEnclosure(String enclosure) {
    this.enclosure = enclosure;
  }


  public HyperscaleDatasetTableOrFile enclosureEscapeCharacter(String enclosureEscapeCharacter) {
    this.enclosureEscapeCharacter = enclosureEscapeCharacter;
    return this;
  }

   /**
   * The escape character used to escape quote characters (Delimited files only).
   * @return enclosureEscapeCharacter
  **/
  @javax.annotation.Nullable
  public String getEnclosureEscapeCharacter() {
    return enclosureEscapeCharacter;
  }

  public void setEnclosureEscapeCharacter(String enclosureEscapeCharacter) {
    this.enclosureEscapeCharacter = enclosureEscapeCharacter;
  }


  public HyperscaleDatasetTableOrFile escapeEnclosureEscapeCharacter(Boolean escapeEnclosureEscapeCharacter) {
    this.escapeEnclosureEscapeCharacter = escapeEnclosureEscapeCharacter;
    return this;
  }

   /**
   * Whether to escape the enclosure escape character (Delimited files only).
   * @return escapeEnclosureEscapeCharacter
  **/
  @javax.annotation.Nullable
  public Boolean getEscapeEnclosureEscapeCharacter() {
    return escapeEnclosureEscapeCharacter;
  }

  public void setEscapeEnclosureEscapeCharacter(Boolean escapeEnclosureEscapeCharacter) {
    this.escapeEnclosureEscapeCharacter = escapeEnclosureEscapeCharacter;
  }


  public HyperscaleDatasetTableOrFile hasHeaders(Boolean hasHeaders) {
    this.hasHeaders = hasHeaders;
    return this;
  }

   /**
   * Whether source files have header column names or not (Delimited files only). If set to true, format files with the same column names are created and the same can be used for the masking inventory. If set to false, the column names of pattern f0, f1, f2, and so on are used to create the format files for delimited file masking.
   * @return hasHeaders
  **/
  @javax.annotation.Nullable
  public Boolean getHasHeaders() {
    return hasHeaders;
  }

  public void setHasHeaders(Boolean hasHeaders) {
    this.hasHeaders = hasHeaders;
  }


  public HyperscaleDatasetTableOrFile uniqueSourceFilesIdentifier(String uniqueSourceFilesIdentifier) {
    this.uniqueSourceFilesIdentifier = uniqueSourceFilesIdentifier;
    return this;
  }

   /**
   * This is the source key that maps the load-service and masking-service data sets with the unload-service data set (Delimited files only). Please ensure that this value is different for each HyperscaleDatasetTableOrFile.
   * @return uniqueSourceFilesIdentifier
  **/
  @javax.annotation.Nullable
  public String getUniqueSourceFilesIdentifier() {
    return uniqueSourceFilesIdentifier;
  }

  public void setUniqueSourceFilesIdentifier(String uniqueSourceFilesIdentifier) {
    this.uniqueSourceFilesIdentifier = uniqueSourceFilesIdentifier;
  }


  public HyperscaleDatasetTableOrFile sourceFiles(List<String> sourceFiles) {
    this.sourceFiles = sourceFiles;
    return this;
  }

  public HyperscaleDatasetTableOrFile addSourceFilesItem(String sourceFilesItem) {
    if (this.sourceFiles == null) {
      this.sourceFiles = new ArrayList<>();
    }
    this.sourceFiles.add(sourceFilesItem);
    return this;
  }

   /**
   * List of all source files that need to be masked (Delimited files only). All files should have the same delimiter character and other helper characters. All files should have the same number of columns and same column names if it has a header line.
   * @return sourceFiles
  **/
  @javax.annotation.Nullable
  public List<String> getSourceFiles() {
    return sourceFiles;
  }

  public void setSourceFiles(List<String> sourceFiles) {
    this.sourceFiles = sourceFiles;
  }


  public HyperscaleDatasetTableOrFile performJoin(Boolean performJoin) {
    this.performJoin = performJoin;
    return this;
  }

   /**
   * Whether the split files must be joined (Delimited files only).
   * @return performJoin
  **/
  @javax.annotation.Nullable
  public Boolean getPerformJoin() {
    return performJoin;
  }

  public void setPerformJoin(Boolean performJoin) {
    this.performJoin = performJoin;
  }


  public HyperscaleDatasetTableOrFile maskingInventory(List<HyperscaleColumnOrField> maskingInventory) {
    this.maskingInventory = maskingInventory;
    return this;
  }

  public HyperscaleDatasetTableOrFile addMaskingInventoryItem(HyperscaleColumnOrField maskingInventoryItem) {
    if (this.maskingInventory == null) {
      this.maskingInventory = new ArrayList<>();
    }
    this.maskingInventory.add(maskingInventoryItem);
    return this;
  }

   /**
   * DataSet information for masking inventory.
   * @return maskingInventory
  **/
  @javax.annotation.Nullable
  public List<HyperscaleColumnOrField> getMaskingInventory() {
    return maskingInventory;
  }

  public void setMaskingInventory(List<HyperscaleColumnOrField> maskingInventory) {
    this.maskingInventory = maskingInventory;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    HyperscaleDatasetTableOrFile hyperscaleDatasetTableOrFile = (HyperscaleDatasetTableOrFile) o;
    return Objects.equals(this.id, hyperscaleDatasetTableOrFile.id) &&
        Objects.equals(this.schemaName, hyperscaleDatasetTableOrFile.schemaName) &&
        Objects.equals(this.tableName, hyperscaleDatasetTableOrFile.tableName) &&
        Objects.equals(this.collectionName, hyperscaleDatasetTableOrFile.collectionName) &&
        Objects.equals(this.databaseName, hyperscaleDatasetTableOrFile.databaseName) &&
        Objects.equals(this.filterKey, hyperscaleDatasetTableOrFile.filterKey) &&
        Objects.equals(this.columnArrayRows, hyperscaleDatasetTableOrFile.columnArrayRows) &&
        Objects.equals(this.unloadSplit, hyperscaleDatasetTableOrFile.unloadSplit) &&
        Objects.equals(this.streamSize, hyperscaleDatasetTableOrFile.streamSize) &&
        Objects.equals(this.endOfRecord, hyperscaleDatasetTableOrFile.endOfRecord) &&
        Objects.equals(this.delimiter, hyperscaleDatasetTableOrFile.delimiter) &&
        Objects.equals(this.enclosure, hyperscaleDatasetTableOrFile.enclosure) &&
        Objects.equals(this.enclosureEscapeCharacter, hyperscaleDatasetTableOrFile.enclosureEscapeCharacter) &&
        Objects.equals(this.escapeEnclosureEscapeCharacter, hyperscaleDatasetTableOrFile.escapeEnclosureEscapeCharacter) &&
        Objects.equals(this.hasHeaders, hyperscaleDatasetTableOrFile.hasHeaders) &&
        Objects.equals(this.uniqueSourceFilesIdentifier, hyperscaleDatasetTableOrFile.uniqueSourceFilesIdentifier) &&
        Objects.equals(this.sourceFiles, hyperscaleDatasetTableOrFile.sourceFiles) &&
        Objects.equals(this.performJoin, hyperscaleDatasetTableOrFile.performJoin) &&
        Objects.equals(this.maskingInventory, hyperscaleDatasetTableOrFile.maskingInventory);
  }

  @Override
  public int hashCode() {
    return Objects.hash(id, schemaName, tableName, collectionName, databaseName, filterKey, columnArrayRows, unloadSplit, streamSize, endOfRecord, delimiter, enclosure, enclosureEscapeCharacter, escapeEnclosureEscapeCharacter, hasHeaders, uniqueSourceFilesIdentifier, sourceFiles, performJoin, maskingInventory);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class HyperscaleDatasetTableOrFile {\n");
    sb.append("    id: ").append(toIndentedString(id)).append("\n");
    sb.append("    schemaName: ").append(toIndentedString(schemaName)).append("\n");
    sb.append("    tableName: ").append(toIndentedString(tableName)).append("\n");
    sb.append("    collectionName: ").append(toIndentedString(collectionName)).append("\n");
    sb.append("    databaseName: ").append(toIndentedString(databaseName)).append("\n");
    sb.append("    filterKey: ").append(toIndentedString(filterKey)).append("\n");
    sb.append("    columnArrayRows: ").append(toIndentedString(columnArrayRows)).append("\n");
    sb.append("    unloadSplit: ").append(toIndentedString(unloadSplit)).append("\n");
    sb.append("    streamSize: ").append(toIndentedString(streamSize)).append("\n");
    sb.append("    endOfRecord: ").append(toIndentedString(endOfRecord)).append("\n");
    sb.append("    delimiter: ").append(toIndentedString(delimiter)).append("\n");
    sb.append("    enclosure: ").append(toIndentedString(enclosure)).append("\n");
    sb.append("    enclosureEscapeCharacter: ").append(toIndentedString(enclosureEscapeCharacter)).append("\n");
    sb.append("    escapeEnclosureEscapeCharacter: ").append(toIndentedString(escapeEnclosureEscapeCharacter)).append("\n");
    sb.append("    hasHeaders: ").append(toIndentedString(hasHeaders)).append("\n");
    sb.append("    uniqueSourceFilesIdentifier: ").append(toIndentedString(uniqueSourceFilesIdentifier)).append("\n");
    sb.append("    sourceFiles: ").append(toIndentedString(sourceFiles)).append("\n");
    sb.append("    performJoin: ").append(toIndentedString(performJoin)).append("\n");
    sb.append("    maskingInventory: ").append(toIndentedString(maskingInventory)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("id");
    openapiFields.add("schema_name");
    openapiFields.add("table_name");
    openapiFields.add("collection_name");
    openapiFields.add("database_name");
    openapiFields.add("filter_key");
    openapiFields.add("column_array_rows");
    openapiFields.add("unload_split");
    openapiFields.add("stream_size");
    openapiFields.add("end_of_record");
    openapiFields.add("delimiter");
    openapiFields.add("enclosure");
    openapiFields.add("enclosure_escape_character");
    openapiFields.add("escape_enclosure_escape_character");
    openapiFields.add("has_headers");
    openapiFields.add("unique_source_files_identifier");
    openapiFields.add("source_files");
    openapiFields.add("perform_join");
    openapiFields.add("masking_inventory");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

 /**
  * Validates the JSON Element and throws an exception if issues found
  *
  * @param jsonElement JSON Element
  * @throws IOException if the JSON Element is invalid with respect to HyperscaleDatasetTableOrFile
  */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!HyperscaleDatasetTableOrFile.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in HyperscaleDatasetTableOrFile is not found in the empty JSON string", HyperscaleDatasetTableOrFile.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!HyperscaleDatasetTableOrFile.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `HyperscaleDatasetTableOrFile` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      if ((jsonObj.get("id") != null && !jsonObj.get("id").isJsonNull()) && !jsonObj.get("id").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `id` to be a primitive type in the JSON string but got `%s`", jsonObj.get("id").toString()));
      }
      if ((jsonObj.get("schema_name") != null && !jsonObj.get("schema_name").isJsonNull()) && !jsonObj.get("schema_name").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `schema_name` to be a primitive type in the JSON string but got `%s`", jsonObj.get("schema_name").toString()));
      }
      if ((jsonObj.get("table_name") != null && !jsonObj.get("table_name").isJsonNull()) && !jsonObj.get("table_name").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `table_name` to be a primitive type in the JSON string but got `%s`", jsonObj.get("table_name").toString()));
      }
      if ((jsonObj.get("collection_name") != null && !jsonObj.get("collection_name").isJsonNull()) && !jsonObj.get("collection_name").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `collection_name` to be a primitive type in the JSON string but got `%s`", jsonObj.get("collection_name").toString()));
      }
      if ((jsonObj.get("database_name") != null && !jsonObj.get("database_name").isJsonNull()) && !jsonObj.get("database_name").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `database_name` to be a primitive type in the JSON string but got `%s`", jsonObj.get("database_name").toString()));
      }
      if ((jsonObj.get("filter_key") != null && !jsonObj.get("filter_key").isJsonNull()) && !jsonObj.get("filter_key").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `filter_key` to be a primitive type in the JSON string but got `%s`", jsonObj.get("filter_key").toString()));
      }
      if ((jsonObj.get("end_of_record") != null && !jsonObj.get("end_of_record").isJsonNull()) && !jsonObj.get("end_of_record").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `end_of_record` to be a primitive type in the JSON string but got `%s`", jsonObj.get("end_of_record").toString()));
      }
      if ((jsonObj.get("delimiter") != null && !jsonObj.get("delimiter").isJsonNull()) && !jsonObj.get("delimiter").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `delimiter` to be a primitive type in the JSON string but got `%s`", jsonObj.get("delimiter").toString()));
      }
      if ((jsonObj.get("enclosure") != null && !jsonObj.get("enclosure").isJsonNull()) && !jsonObj.get("enclosure").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `enclosure` to be a primitive type in the JSON string but got `%s`", jsonObj.get("enclosure").toString()));
      }
      if ((jsonObj.get("enclosure_escape_character") != null && !jsonObj.get("enclosure_escape_character").isJsonNull()) && !jsonObj.get("enclosure_escape_character").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `enclosure_escape_character` to be a primitive type in the JSON string but got `%s`", jsonObj.get("enclosure_escape_character").toString()));
      }
      if ((jsonObj.get("unique_source_files_identifier") != null && !jsonObj.get("unique_source_files_identifier").isJsonNull()) && !jsonObj.get("unique_source_files_identifier").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `unique_source_files_identifier` to be a primitive type in the JSON string but got `%s`", jsonObj.get("unique_source_files_identifier").toString()));
      }
      // ensure the optional json data is an array if present
      if (jsonObj.get("source_files") != null && !jsonObj.get("source_files").isJsonNull() && !jsonObj.get("source_files").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `source_files` to be an array in the JSON string but got `%s`", jsonObj.get("source_files").toString()));
      }
      if (jsonObj.get("masking_inventory") != null && !jsonObj.get("masking_inventory").isJsonNull()) {
        JsonArray jsonArraymaskingInventory = jsonObj.getAsJsonArray("masking_inventory");
        if (jsonArraymaskingInventory != null) {
          // ensure the json data is an array
          if (!jsonObj.get("masking_inventory").isJsonArray()) {
            throw new IllegalArgumentException(String.format("Expected the field `masking_inventory` to be an array in the JSON string but got `%s`", jsonObj.get("masking_inventory").toString()));
          }

          // validate the optional field `masking_inventory` (array)
          for (int i = 0; i < jsonArraymaskingInventory.size(); i++) {
            HyperscaleColumnOrField.validateJsonElement(jsonArraymaskingInventory.get(i));
          };
        }
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!HyperscaleDatasetTableOrFile.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'HyperscaleDatasetTableOrFile' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<HyperscaleDatasetTableOrFile> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(HyperscaleDatasetTableOrFile.class));

       return (TypeAdapter<T>) new TypeAdapter<HyperscaleDatasetTableOrFile>() {
           @Override
           public void write(JsonWriter out, HyperscaleDatasetTableOrFile value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public HyperscaleDatasetTableOrFile read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

 /**
  * Create an instance of HyperscaleDatasetTableOrFile given an JSON string
  *
  * @param jsonString JSON string
  * @return An instance of HyperscaleDatasetTableOrFile
  * @throws IOException if the JSON string is invalid with respect to HyperscaleDatasetTableOrFile
  */
  public static HyperscaleDatasetTableOrFile fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, HyperscaleDatasetTableOrFile.class);
  }

 /**
  * Convert an instance of HyperscaleDatasetTableOrFile to an JSON string
  *
  * @return JSON string
  */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

