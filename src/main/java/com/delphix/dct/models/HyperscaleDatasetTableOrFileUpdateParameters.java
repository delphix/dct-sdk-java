/*
 * Delphix DCT API
 * Delphix DCT API
 *
 * The version of the OpenAPI document: 3.10.0
 * Contact: support@delphix.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package com.delphix.dct.models;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import com.google.gson.Gson;
import com.google.gson.GsonBuilder;
import com.google.gson.JsonArray;
import com.google.gson.JsonDeserializationContext;
import com.google.gson.JsonDeserializer;
import com.google.gson.JsonElement;
import com.google.gson.JsonObject;
import com.google.gson.JsonParseException;
import com.google.gson.TypeAdapterFactory;
import com.google.gson.reflect.TypeToken;
import com.google.gson.TypeAdapter;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import java.io.IOException;

import java.lang.reflect.Type;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import com.delphix.dct.JSON;

/**
 * The updatable properties of a table or file which is part of a hyperscale dataset.
 */
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen", date = "2024-04-04T14:49:34.152994+05:30[Asia/Kolkata]", comments = "Generator version: 7.4.0")
public class HyperscaleDatasetTableOrFileUpdateParameters {
  public static final String SERIALIZED_NAME_FILTER_KEY = "filter_key";
  @SerializedName(SERIALIZED_NAME_FILTER_KEY)
  private String filterKey;

  public static final String SERIALIZED_NAME_COLUMN_ARRAY_ROWS = "column_array_rows";
  @SerializedName(SERIALIZED_NAME_COLUMN_ARRAY_ROWS)
  private Long columnArrayRows;

  public static final String SERIALIZED_NAME_UNLOAD_SPLIT = "unload_split";
  @SerializedName(SERIALIZED_NAME_UNLOAD_SPLIT)
  private Long unloadSplit;

  public static final String SERIALIZED_NAME_STREAM_SIZE = "stream_size";
  @SerializedName(SERIALIZED_NAME_STREAM_SIZE)
  private Long streamSize;

  public static final String SERIALIZED_NAME_END_OF_RECORD = "end_of_record";
  @SerializedName(SERIALIZED_NAME_END_OF_RECORD)
  private String endOfRecord;

  public static final String SERIALIZED_NAME_DELIMITER = "delimiter";
  @SerializedName(SERIALIZED_NAME_DELIMITER)
  private String delimiter;

  public static final String SERIALIZED_NAME_ENCLOSURE = "enclosure";
  @SerializedName(SERIALIZED_NAME_ENCLOSURE)
  private String enclosure;

  public static final String SERIALIZED_NAME_ENCLOSURE_ESCAPE_CHARACTER = "enclosure_escape_character";
  @SerializedName(SERIALIZED_NAME_ENCLOSURE_ESCAPE_CHARACTER)
  private String enclosureEscapeCharacter;

  public static final String SERIALIZED_NAME_ESCAPE_ENCLOSURE_ESCAPE_CHARACTER = "escape_enclosure_escape_character";
  @SerializedName(SERIALIZED_NAME_ESCAPE_ENCLOSURE_ESCAPE_CHARACTER)
  private Boolean escapeEnclosureEscapeCharacter;

  public static final String SERIALIZED_NAME_HAS_HEADERS = "has_headers";
  @SerializedName(SERIALIZED_NAME_HAS_HEADERS)
  private Boolean hasHeaders;

  public static final String SERIALIZED_NAME_UNIQUE_SOURCE_FILES_IDENTIFIER = "unique_source_files_identifier";
  @SerializedName(SERIALIZED_NAME_UNIQUE_SOURCE_FILES_IDENTIFIER)
  private String uniqueSourceFilesIdentifier;

  public static final String SERIALIZED_NAME_SOURCE_FILES = "source_files";
  @SerializedName(SERIALIZED_NAME_SOURCE_FILES)
  private List<String> sourceFiles;

  public static final String SERIALIZED_NAME_PERFORM_JOIN = "perform_join";
  @SerializedName(SERIALIZED_NAME_PERFORM_JOIN)
  private Boolean performJoin;

  public HyperscaleDatasetTableOrFileUpdateParameters() {
  }

  public HyperscaleDatasetTableOrFileUpdateParameters filterKey(String filterKey) {
    this.filterKey = filterKey;
    return this;
  }

   /**
   * The unique database column field to filter the source data. Set this property to an empty string to clear the value.
   * @return filterKey
  **/
  @javax.annotation.Nullable
  public String getFilterKey() {
    return filterKey;
  }

  public void setFilterKey(String filterKey) {
    this.filterKey = filterKey;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters columnArrayRows(Long columnArrayRows) {
    this.columnArrayRows = columnArrayRows;
    return this;
  }

   /**
   * The number of column array rows to be used by the sqlldr oracle utility which determines the number of rows loaded before the stream buffer is built.
   * @return columnArrayRows
  **/
  @javax.annotation.Nullable
  public Long getColumnArrayRows() {
    return columnArrayRows;
  }

  public void setColumnArrayRows(Long columnArrayRows) {
    this.columnArrayRows = columnArrayRows;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters unloadSplit(Long unloadSplit) {
    this.unloadSplit = unloadSplit;
    return this;
  }

   /**
   * The number of unloaded files to be generated from the source database.
   * @return unloadSplit
  **/
  @javax.annotation.Nullable
  public Long getUnloadSplit() {
    return unloadSplit;
  }

  public void setUnloadSplit(Long unloadSplit) {
    this.unloadSplit = unloadSplit;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters streamSize(Long streamSize) {
    this.streamSize = streamSize;
    return this;
  }

   /**
   * Long The stream size to be used by the sqlldr oracle utility which specifies the size (in bytes) of the data stream sent from the client to the server.
   * @return streamSize
  **/
  @javax.annotation.Nullable
  public Long getStreamSize() {
    return streamSize;
  }

  public void setStreamSize(Long streamSize) {
    this.streamSize = streamSize;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters endOfRecord(String endOfRecord) {
    this.endOfRecord = endOfRecord;
    return this;
  }

   /**
   * The end of line character. Support values are \\n, \\r  and \\r\\n (Delimited files only).
   * @return endOfRecord
  **/
  @javax.annotation.Nullable
  public String getEndOfRecord() {
    return endOfRecord;
  }

  public void setEndOfRecord(String endOfRecord) {
    this.endOfRecord = endOfRecord;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters delimiter(String delimiter) {
    this.delimiter = delimiter;
    return this;
  }

   /**
   * The single character length delimiter used in source files (Delimited files only).
   * @return delimiter
  **/
  @javax.annotation.Nullable
  public String getDelimiter() {
    return delimiter;
  }

  public void setDelimiter(String delimiter) {
    this.delimiter = delimiter;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters enclosure(String enclosure) {
    this.enclosure = enclosure;
    return this;
  }

   /**
   * The single character length quote character used in the source files (Delimited files only).
   * @return enclosure
  **/
  @javax.annotation.Nullable
  public String getEnclosure() {
    return enclosure;
  }

  public void setEnclosure(String enclosure) {
    this.enclosure = enclosure;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters enclosureEscapeCharacter(String enclosureEscapeCharacter) {
    this.enclosureEscapeCharacter = enclosureEscapeCharacter;
    return this;
  }

   /**
   * The escape character used to escape quote characters (Delimited files only).
   * @return enclosureEscapeCharacter
  **/
  @javax.annotation.Nullable
  public String getEnclosureEscapeCharacter() {
    return enclosureEscapeCharacter;
  }

  public void setEnclosureEscapeCharacter(String enclosureEscapeCharacter) {
    this.enclosureEscapeCharacter = enclosureEscapeCharacter;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters escapeEnclosureEscapeCharacter(Boolean escapeEnclosureEscapeCharacter) {
    this.escapeEnclosureEscapeCharacter = escapeEnclosureEscapeCharacter;
    return this;
  }

   /**
   * Whether to escape the enclosure escape character (Delimited files only).
   * @return escapeEnclosureEscapeCharacter
  **/
  @javax.annotation.Nullable
  public Boolean getEscapeEnclosureEscapeCharacter() {
    return escapeEnclosureEscapeCharacter;
  }

  public void setEscapeEnclosureEscapeCharacter(Boolean escapeEnclosureEscapeCharacter) {
    this.escapeEnclosureEscapeCharacter = escapeEnclosureEscapeCharacter;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters hasHeaders(Boolean hasHeaders) {
    this.hasHeaders = hasHeaders;
    return this;
  }

   /**
   * Whether source files have header column names or not (Delimited files only). If set to true, format files with the same column names are created and the same can be used for the masking inventory. If set to false, the column names of pattern f0, f1, f2, and so on are used to create the format files for delimited file masking.
   * @return hasHeaders
  **/
  @javax.annotation.Nullable
  public Boolean getHasHeaders() {
    return hasHeaders;
  }

  public void setHasHeaders(Boolean hasHeaders) {
    this.hasHeaders = hasHeaders;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters uniqueSourceFilesIdentifier(String uniqueSourceFilesIdentifier) {
    this.uniqueSourceFilesIdentifier = uniqueSourceFilesIdentifier;
    return this;
  }

   /**
   * This is the source key that maps the load-service and masking-service data sets with the unload-service data set (Delimited files only). Please ensure that this value is different for each HyperscaleDatasetTableOrFile.
   * @return uniqueSourceFilesIdentifier
  **/
  @javax.annotation.Nullable
  public String getUniqueSourceFilesIdentifier() {
    return uniqueSourceFilesIdentifier;
  }

  public void setUniqueSourceFilesIdentifier(String uniqueSourceFilesIdentifier) {
    this.uniqueSourceFilesIdentifier = uniqueSourceFilesIdentifier;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters sourceFiles(List<String> sourceFiles) {
    this.sourceFiles = sourceFiles;
    return this;
  }

  public HyperscaleDatasetTableOrFileUpdateParameters addSourceFilesItem(String sourceFilesItem) {
    if (this.sourceFiles == null) {
      this.sourceFiles = new ArrayList<>();
    }
    this.sourceFiles.add(sourceFilesItem);
    return this;
  }

   /**
   * List of all source files that need to be masked (Delimited files only). All files should have the same delimiter character and other helper characters. All files should have the same number of columns and same column names if it has a header line.
   * @return sourceFiles
  **/
  @javax.annotation.Nullable
  public List<String> getSourceFiles() {
    return sourceFiles;
  }

  public void setSourceFiles(List<String> sourceFiles) {
    this.sourceFiles = sourceFiles;
  }


  public HyperscaleDatasetTableOrFileUpdateParameters performJoin(Boolean performJoin) {
    this.performJoin = performJoin;
    return this;
  }

   /**
   * Whether the split files must be joined (Delimited files only).
   * @return performJoin
  **/
  @javax.annotation.Nullable
  public Boolean getPerformJoin() {
    return performJoin;
  }

  public void setPerformJoin(Boolean performJoin) {
    this.performJoin = performJoin;
  }



  @Override
  public boolean equals(Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    HyperscaleDatasetTableOrFileUpdateParameters hyperscaleDatasetTableOrFileUpdateParameters = (HyperscaleDatasetTableOrFileUpdateParameters) o;
    return Objects.equals(this.filterKey, hyperscaleDatasetTableOrFileUpdateParameters.filterKey) &&
        Objects.equals(this.columnArrayRows, hyperscaleDatasetTableOrFileUpdateParameters.columnArrayRows) &&
        Objects.equals(this.unloadSplit, hyperscaleDatasetTableOrFileUpdateParameters.unloadSplit) &&
        Objects.equals(this.streamSize, hyperscaleDatasetTableOrFileUpdateParameters.streamSize) &&
        Objects.equals(this.endOfRecord, hyperscaleDatasetTableOrFileUpdateParameters.endOfRecord) &&
        Objects.equals(this.delimiter, hyperscaleDatasetTableOrFileUpdateParameters.delimiter) &&
        Objects.equals(this.enclosure, hyperscaleDatasetTableOrFileUpdateParameters.enclosure) &&
        Objects.equals(this.enclosureEscapeCharacter, hyperscaleDatasetTableOrFileUpdateParameters.enclosureEscapeCharacter) &&
        Objects.equals(this.escapeEnclosureEscapeCharacter, hyperscaleDatasetTableOrFileUpdateParameters.escapeEnclosureEscapeCharacter) &&
        Objects.equals(this.hasHeaders, hyperscaleDatasetTableOrFileUpdateParameters.hasHeaders) &&
        Objects.equals(this.uniqueSourceFilesIdentifier, hyperscaleDatasetTableOrFileUpdateParameters.uniqueSourceFilesIdentifier) &&
        Objects.equals(this.sourceFiles, hyperscaleDatasetTableOrFileUpdateParameters.sourceFiles) &&
        Objects.equals(this.performJoin, hyperscaleDatasetTableOrFileUpdateParameters.performJoin);
  }

  @Override
  public int hashCode() {
    return Objects.hash(filterKey, columnArrayRows, unloadSplit, streamSize, endOfRecord, delimiter, enclosure, enclosureEscapeCharacter, escapeEnclosureEscapeCharacter, hasHeaders, uniqueSourceFilesIdentifier, sourceFiles, performJoin);
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class HyperscaleDatasetTableOrFileUpdateParameters {\n");
    sb.append("    filterKey: ").append(toIndentedString(filterKey)).append("\n");
    sb.append("    columnArrayRows: ").append(toIndentedString(columnArrayRows)).append("\n");
    sb.append("    unloadSplit: ").append(toIndentedString(unloadSplit)).append("\n");
    sb.append("    streamSize: ").append(toIndentedString(streamSize)).append("\n");
    sb.append("    endOfRecord: ").append(toIndentedString(endOfRecord)).append("\n");
    sb.append("    delimiter: ").append(toIndentedString(delimiter)).append("\n");
    sb.append("    enclosure: ").append(toIndentedString(enclosure)).append("\n");
    sb.append("    enclosureEscapeCharacter: ").append(toIndentedString(enclosureEscapeCharacter)).append("\n");
    sb.append("    escapeEnclosureEscapeCharacter: ").append(toIndentedString(escapeEnclosureEscapeCharacter)).append("\n");
    sb.append("    hasHeaders: ").append(toIndentedString(hasHeaders)).append("\n");
    sb.append("    uniqueSourceFilesIdentifier: ").append(toIndentedString(uniqueSourceFilesIdentifier)).append("\n");
    sb.append("    sourceFiles: ").append(toIndentedString(sourceFiles)).append("\n");
    sb.append("    performJoin: ").append(toIndentedString(performJoin)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }


  public static HashSet<String> openapiFields;
  public static HashSet<String> openapiRequiredFields;

  static {
    // a set of all properties/fields (JSON key names)
    openapiFields = new HashSet<String>();
    openapiFields.add("filter_key");
    openapiFields.add("column_array_rows");
    openapiFields.add("unload_split");
    openapiFields.add("stream_size");
    openapiFields.add("end_of_record");
    openapiFields.add("delimiter");
    openapiFields.add("enclosure");
    openapiFields.add("enclosure_escape_character");
    openapiFields.add("escape_enclosure_escape_character");
    openapiFields.add("has_headers");
    openapiFields.add("unique_source_files_identifier");
    openapiFields.add("source_files");
    openapiFields.add("perform_join");

    // a set of required properties/fields (JSON key names)
    openapiRequiredFields = new HashSet<String>();
  }

 /**
  * Validates the JSON Element and throws an exception if issues found
  *
  * @param jsonElement JSON Element
  * @throws IOException if the JSON Element is invalid with respect to HyperscaleDatasetTableOrFileUpdateParameters
  */
  public static void validateJsonElement(JsonElement jsonElement) throws IOException {
      if (jsonElement == null) {
        if (!HyperscaleDatasetTableOrFileUpdateParameters.openapiRequiredFields.isEmpty()) { // has required fields but JSON element is null
          throw new IllegalArgumentException(String.format("The required field(s) %s in HyperscaleDatasetTableOrFileUpdateParameters is not found in the empty JSON string", HyperscaleDatasetTableOrFileUpdateParameters.openapiRequiredFields.toString()));
        }
      }

      Set<Map.Entry<String, JsonElement>> entries = jsonElement.getAsJsonObject().entrySet();
      // check to see if the JSON string contains additional fields
      for (Map.Entry<String, JsonElement> entry : entries) {
        if (!HyperscaleDatasetTableOrFileUpdateParameters.openapiFields.contains(entry.getKey())) {
          throw new IllegalArgumentException(String.format("The field `%s` in the JSON string is not defined in the `HyperscaleDatasetTableOrFileUpdateParameters` properties. JSON: %s", entry.getKey(), jsonElement.toString()));
        }
      }
        JsonObject jsonObj = jsonElement.getAsJsonObject();
      if ((jsonObj.get("filter_key") != null && !jsonObj.get("filter_key").isJsonNull()) && !jsonObj.get("filter_key").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `filter_key` to be a primitive type in the JSON string but got `%s`", jsonObj.get("filter_key").toString()));
      }
      if ((jsonObj.get("end_of_record") != null && !jsonObj.get("end_of_record").isJsonNull()) && !jsonObj.get("end_of_record").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `end_of_record` to be a primitive type in the JSON string but got `%s`", jsonObj.get("end_of_record").toString()));
      }
      if ((jsonObj.get("delimiter") != null && !jsonObj.get("delimiter").isJsonNull()) && !jsonObj.get("delimiter").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `delimiter` to be a primitive type in the JSON string but got `%s`", jsonObj.get("delimiter").toString()));
      }
      if ((jsonObj.get("enclosure") != null && !jsonObj.get("enclosure").isJsonNull()) && !jsonObj.get("enclosure").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `enclosure` to be a primitive type in the JSON string but got `%s`", jsonObj.get("enclosure").toString()));
      }
      if ((jsonObj.get("enclosure_escape_character") != null && !jsonObj.get("enclosure_escape_character").isJsonNull()) && !jsonObj.get("enclosure_escape_character").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `enclosure_escape_character` to be a primitive type in the JSON string but got `%s`", jsonObj.get("enclosure_escape_character").toString()));
      }
      if ((jsonObj.get("unique_source_files_identifier") != null && !jsonObj.get("unique_source_files_identifier").isJsonNull()) && !jsonObj.get("unique_source_files_identifier").isJsonPrimitive()) {
        throw new IllegalArgumentException(String.format("Expected the field `unique_source_files_identifier` to be a primitive type in the JSON string but got `%s`", jsonObj.get("unique_source_files_identifier").toString()));
      }
      // ensure the optional json data is an array if present
      if (jsonObj.get("source_files") != null && !jsonObj.get("source_files").isJsonNull() && !jsonObj.get("source_files").isJsonArray()) {
        throw new IllegalArgumentException(String.format("Expected the field `source_files` to be an array in the JSON string but got `%s`", jsonObj.get("source_files").toString()));
      }
  }

  public static class CustomTypeAdapterFactory implements TypeAdapterFactory {
    @SuppressWarnings("unchecked")
    @Override
    public <T> TypeAdapter<T> create(Gson gson, TypeToken<T> type) {
       if (!HyperscaleDatasetTableOrFileUpdateParameters.class.isAssignableFrom(type.getRawType())) {
         return null; // this class only serializes 'HyperscaleDatasetTableOrFileUpdateParameters' and its subtypes
       }
       final TypeAdapter<JsonElement> elementAdapter = gson.getAdapter(JsonElement.class);
       final TypeAdapter<HyperscaleDatasetTableOrFileUpdateParameters> thisAdapter
                        = gson.getDelegateAdapter(this, TypeToken.get(HyperscaleDatasetTableOrFileUpdateParameters.class));

       return (TypeAdapter<T>) new TypeAdapter<HyperscaleDatasetTableOrFileUpdateParameters>() {
           @Override
           public void write(JsonWriter out, HyperscaleDatasetTableOrFileUpdateParameters value) throws IOException {
             JsonObject obj = thisAdapter.toJsonTree(value).getAsJsonObject();
             elementAdapter.write(out, obj);
           }

           @Override
           public HyperscaleDatasetTableOrFileUpdateParameters read(JsonReader in) throws IOException {
             JsonElement jsonElement = elementAdapter.read(in);
             validateJsonElement(jsonElement);
             return thisAdapter.fromJsonTree(jsonElement);
           }

       }.nullSafe();
    }
  }

 /**
  * Create an instance of HyperscaleDatasetTableOrFileUpdateParameters given an JSON string
  *
  * @param jsonString JSON string
  * @return An instance of HyperscaleDatasetTableOrFileUpdateParameters
  * @throws IOException if the JSON string is invalid with respect to HyperscaleDatasetTableOrFileUpdateParameters
  */
  public static HyperscaleDatasetTableOrFileUpdateParameters fromJson(String jsonString) throws IOException {
    return JSON.getGson().fromJson(jsonString, HyperscaleDatasetTableOrFileUpdateParameters.class);
  }

 /**
  * Convert an instance of HyperscaleDatasetTableOrFileUpdateParameters to an JSON string
  *
  * @return JSON string
  */
  public String toJson() {
    return JSON.getGson().toJson(this);
  }
}

